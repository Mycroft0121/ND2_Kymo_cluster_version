{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kymograph generator  -- O2 Cluster Version\n",
    "author: Suyang Wan\n",
    "product manager: Emanuele Leoncini, Somenath Bakshi\n",
    "Special thanks for technical support: Carlos Sanchez, Sadik Yidik\n",
    "\n",
    "## Library dependence:\n",
    "use nd2reader 2.1.3, don't use the new version!!!!!\n",
    "library install instructions:\n",
    "In terminal, type:\n",
    "nd2reader: In terminal, type: \"pip install \"nd2reader==2.1.3\"\" or \"pip3 install \"nd2reader==2.1.3\"\" \n",
    "PIL: In terminal, type: \"pip install Pillow\" or \"pip3 install Pillow\"\n",
    "pims: In terminal, type: \"pip install pims_nd2\" or \"pip3 install pims_nd2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't touch me!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import glob  # pathname pattern\n",
    "from PIL import Image\n",
    "import nd2reader\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "from pims import ND2_Reader\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import pathos.multiprocessing\n",
    "import multiprocessing\n",
    "import resource\n",
    "\n",
    "from datetime import datetime\n",
    "import h5py\n",
    "from tifffile import imsave\n",
    "from skimage import filters\n",
    "from skimage import io as skio\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.signal import medfilt\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "from PIL import Image, ImageEnhance\n",
    "import shutil,itertools\n",
    "from itertools import count\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from bokeh.models import HoverTool\n",
    "import holoviews as hv\n",
    "\n",
    "\n",
    "class trench_kymograph():\n",
    "    def __init__(self, nd2_file, main_directory, lane, pos, seg_channel, other_channels,\n",
    "                 spatial,trench_length=None, trench_width=None,\n",
    "                correct_drift=0, found_drift = 0, frame_start=None, frame_limit=None, output_dir=None,\n",
    "                 box_info=None, saving_option = 0, clean_up=1, chip_length=None, chip_width=None, magnification = None, template=None,kymo_enhanced=0):\n",
    "        self.prefix = nd2_file[:-4]\n",
    "        self.main_path = main_directory\n",
    "        self.lane = lane\n",
    "#         self.channel = channel\n",
    "        self.seg_channel = seg_channel\n",
    "        self.pos = pos\n",
    "        self.trench_length = trench_length\n",
    "        self.trench_width = trench_width\n",
    "        self.frame_start = frame_start\n",
    "        self.frame_limit = frame_limit\n",
    "        self.correct_drift = correct_drift\n",
    "        self.found_drift = found_drift\n",
    "        self.drift_x = None\n",
    "        self.drift_y = None\n",
    "        self.drift_x_txt = None\n",
    "        self.drift_y_txt = None\n",
    "        self.spatial = spatial  # 0 for top, 1 for bottom, 2 for both\n",
    "        self.tops = []\n",
    "        self.bottoms = []\n",
    "        self.meta = None\n",
    "        self.height = None\n",
    "        self.width = None\n",
    "        self.total_t = None\n",
    "        self.out_file = None\n",
    "        self.box_info = box_info  # file names\n",
    "        self.file_list = None\n",
    "        self.frame_end = None\n",
    "        \n",
    "        \n",
    "        ### new for cluster\n",
    "        other_channels.append(seg_channel)\n",
    "        self.all_channels=other_channels\n",
    "\n",
    "        # new for phase\n",
    "        self.is_stack = 0\n",
    "        self.stack_length = None\n",
    "        self.stack = None\n",
    "        self.file_length = 0\n",
    "        self.cropped_path = None\n",
    "        self.spread = None\n",
    "        self.bad_pos = [0,0]\n",
    "\n",
    "        self.bbox_dict = {}\n",
    "\n",
    "        self.im_projected = None\n",
    "\n",
    "        self.bottom_cut = 0\n",
    "        self.magnification = magnification\n",
    "\n",
    "\n",
    "        self.saving_option = saving_option  # 0 for stack, 1 for kymo, 2 for both, default only save stacks\n",
    "        self.clean = clean_up # whether delete enhanced/cropped, default yes\n",
    "\n",
    "        self.chip_length = chip_length\n",
    "        self.chip_width  = chip_width\n",
    "\n",
    "\n",
    "        ## template matching in phase with\n",
    "        self.template = template   # format[y_top:y_bottom, x_left:x_right]\n",
    "\n",
    "\n",
    "        self.kymo_enhance = kymo_enhanced\n",
    "\n",
    "\n",
    "        # 6.5 is the magic number for Ti3, Ti4\n",
    "        if ((self.trench_length or self.chip_length) is None) or ((self.trench_width or self.chip_width) is None):\n",
    "            print(\"Error: trench dimension not specified\")\n",
    "            #exit()\n",
    "        if not self.trench_length:\n",
    "            if not self.magnification:\n",
    "                print(\"Error: magnification not specified\")\n",
    "                #exit()\n",
    "            self.trench_length = int(self.chip_length/6.5*self.magnification)\n",
    "        if not self.trench_width:\n",
    "            if not self.magnification:\n",
    "                print(\"Error: magnification not specified\")\n",
    "                #exit()\n",
    "            self.trench_width = int((self.chip_width/6.5*self.magnification))\n",
    "            if self.seg_channel !='BF' and self.seg_channel !='Phase':   # if not phase contrast, dilate trench width\n",
    "                self.trench_width *= 1.2\n",
    "\n",
    "        # TODO: change the path pattern if you didn't extract the ND2 with my extractor\n",
    "        self.file_path = self.main_path + \"/\" + self.prefix + \"/Lane_\" + str(self.lane).zfill(2) + \"/pos_\" + str(\n",
    "            self.pos).zfill(3)\n",
    "        if output_dir:\n",
    "            self.output_dir = output_dir\n",
    "        else:\n",
    "            self.output_dir = self.file_path\n",
    "\n",
    "\n",
    "        print(\"Saving option: \" + str(self.saving_option))\n",
    "    ###\n",
    "    # TODO: change the path pattern if you didn't extract the ND2 with my extractor\n",
    "    def get_file_list(self, file_path=None, channel=None, spatial=''):\n",
    "        self.is_stack = 0\n",
    "        # TODO: to deal with multiple stacks\n",
    "        if not file_path:\n",
    "            file_path = self.file_path\n",
    "        if not channel:\n",
    "            channel = self.channel\n",
    "        os.chdir(file_path)\n",
    "\n",
    "        # special case for testing\n",
    "        self.file_list = glob.glob(spatial+'*_c_*' + channel + '*.tif*')\n",
    "        first_file = skio.imread(self.file_list[0])\n",
    "        first_shape = first_file.shape\n",
    "        if len(first_shape) == 3:\n",
    "            self.is_stack = 1\n",
    "            self.stack_length = first_shape[0]\n",
    "            if self.frame_start is None:\n",
    "                self.frame_start = 0\n",
    "            if self.frame_limit is None:\n",
    "                self.frame_end = self.stack_length - self.frame_start\n",
    "            else:\n",
    "                self.frame_end = self.frame_start + self.frame_limit\n",
    "            self.stack = first_file[self.frame_start:self.frame_end, :, :]\n",
    "            [self.height, self.width] = [first_shape[1], first_file.shape[2]]\n",
    "            self.file_length = self.stack.shape[0]\n",
    "\n",
    "        else:\n",
    "            def get_time(name):\n",
    "                # for newly extracted\n",
    "                # sub_name = name.split('_Time_')[1]\n",
    "                # for previously extracted, may also need change if you have \"_t\" in your file name\n",
    "                sub_name = name.split('_Time_')[1]\n",
    "                num = sub_name.split('_c')[0]\n",
    "                return int(num)\n",
    "\n",
    "            self.file_list.sort(key=get_time)\n",
    "\n",
    "            if self.frame_start is None:\n",
    "                self.frame_start = 0\n",
    "            if self.frame_limit is None:\n",
    "                self.frame_end = len(self.file_list)\n",
    "            else:\n",
    "                self.frame_end = self.frame_start + self.frame_limit\n",
    "\n",
    "            self.file_list = self.file_list[self.frame_start:self.frame_end]\n",
    "            [self.height, self.width] = [first_shape[0], first_file.shape[1]]\n",
    "            self.file_length = len(self.file_list)\n",
    "            return\n",
    "\n",
    "    # only for stacks\n",
    "    def get_frame(self, i):\n",
    "        if self.is_stack:\n",
    "            return self.stack[i, :, :]\n",
    "        else:\n",
    "            return pl.imread(self.file_list[i])\n",
    "\n",
    "    def find_drift(self):\n",
    "        lane_path = self.file_path\n",
    "        tops = []\n",
    "        peaks = []\n",
    "        file_num = len(self.file_list)\n",
    "        drift_y = open(lane_path + '/drift_y.txt', 'w')\n",
    "        drift_x = open(lane_path + '/drift_x.txt', 'w')\n",
    "        y_shift = [0]\n",
    "        for i in range(len(self.file_list)):\n",
    "            # print(self.find_top(i))\n",
    "            tops.append(self.find_top(i))\n",
    "\n",
    "        for i in range(len(tops)-1):\n",
    "            diff = 0\n",
    "            # diff = tops[i+1] - tops[i]\n",
    "            # if diff > 10:\n",
    "            #     diff = 0\n",
    "            y_shift.append(diff)\n",
    "\n",
    "        for i in range(len(self.file_list)):\n",
    "            peaks.append(self.find_peaks(i, tops))\n",
    "\n",
    "        # positive: downwards drift\n",
    "        drift_y.write(' '.join(map(str, y_shift)))\n",
    "        # print(y_shift)\n",
    "\n",
    "        x_shift = [0]\n",
    "        for i in range(file_num - 1):\n",
    "            list_a = peaks[i]\n",
    "            list_b = peaks[i + 1]\n",
    "            move = self.pairwise_list_align(list_a, list_b, self.trench_width * 0.75)\n",
    "            x_shift.append(move)\n",
    "\n",
    "        # positive: drift to the right\n",
    "        x_shift = np.cumsum(np.array(x_shift)).astype(int)\n",
    "\n",
    "        drift_x.write(' '.join(map(str, x_shift.tolist())))\n",
    "\n",
    "        self.drift_x = x_shift\n",
    "        self.drift_y = y_shift\n",
    "        self.drift_x_txt = 'drift_x.txt'\n",
    "        self.drift_y_txt = 'drift_y.txt'\n",
    "        self.found_drift = 1\n",
    "        return\n",
    "\n",
    "\n",
    "    def find_drift_phase(self):\n",
    "        lane_path = self.file_path\n",
    "        file_num = len(self.file_list)\n",
    "\n",
    "\n",
    "        drift_y = open(lane_path + '/drift_y.txt', 'w')\n",
    "        drift_x = open(lane_path + '/drift_x.txt', 'w')\n",
    "        x_shift = np.zeros((file_num))\n",
    "        y_shift = np.zeros((file_num))\n",
    "\n",
    "        method = 'cv2.TM_CCOEFF_NORMED'\n",
    "        method = eval(method)\n",
    "        im_prev = self.get_frame(0).astype(np.float32)\n",
    "        template = im_prev[self.template[0]:self.template[1], self.template[2]:self.template[3]]\n",
    "\n",
    "        x_ref = self.template[2]\n",
    "        y_ref = self.template[0]\n",
    "        for i in range(1,file_num):\n",
    "            im_now = self.get_frame(i).astype(np.float32)\n",
    "            res = cv2.matchTemplate(template, im_now, method)\n",
    "\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "            x_shift[i] = max_loc[0] - x_ref\n",
    "            y_shift[i] = max_loc[1] - y_ref\n",
    "            # x_shift[i] = -max_loc[0] + x_ref\n",
    "            # y_shift[i] = -max_loc[1] + y_ref\n",
    "\n",
    "        x_shift = x_shift.astype(int)\n",
    "        y_shift = y_shift.astype(int)\n",
    "        drift_x.write(' '.join(map(str, x_shift.tolist())))\n",
    "        drift_y.write(' '.join(map(str, y_shift.tolist())))\n",
    "\n",
    "        self.drift_x = x_shift\n",
    "        self.drift_y = y_shift\n",
    "        self.drift_x_txt = 'drift_x.txt'\n",
    "        self.drift_y_txt = 'drift_y.txt'\n",
    "        self.found_drift = 1\n",
    "        return\n",
    "\n",
    "\n",
    "    def read_drift(self):\n",
    "        self.drift_x_txt = 'drift_x.txt'\n",
    "        self.drift_y_txt = 'drift_y.txt'\n",
    "        lane_path = self.file_path\n",
    "        # lane_path = self.main_path + \"/\" + self.prefix + \"/Lane_\" + str(self.lane).zfill(2)\n",
    "        self.drift_x_txt = lane_path + \"/\" + self.drift_x_txt\n",
    "        self.drift_y_txt = lane_path + \"/\" + self.drift_y_txt\n",
    "        # read files into np array\n",
    "        self.drift_x = np.loadtxt(self.drift_x_txt, dtype=int, delimiter=' ')\n",
    "        self.drift_y = np.loadtxt(self.drift_y_txt, dtype=int, delimiter=' ')\n",
    "        return\n",
    "\n",
    "    def find_top(self, i):\n",
    "        im_i = pl.imread(self.file_list[i])\n",
    "        if self.seg_channel == \"BF\" or self.seg_channel == \"Phase\":\n",
    "            x_per = np.percentile(im_i, 70, axis=1)\n",
    "        else:\n",
    "            x_per = np.percentile(im_i, 95, axis=1)\n",
    "        intensity_scan = x_per\n",
    "        intensity_scan = intensity_scan / float(sum(intensity_scan))\n",
    "        # normalize intensity\n",
    "        im_min = intensity_scan.min()\n",
    "        im_max = intensity_scan.max()\n",
    "        scaling_factor = (im_max - im_min)\n",
    "        intensity_scan = (intensity_scan - im_min)\n",
    "        intensity_scan = (intensity_scan / scaling_factor)\n",
    "\n",
    "        if self.spatial == 1:\n",
    "            # actually  bottoms, but mie..\n",
    "            top = np.where(intensity_scan > 0.2)[0][-1]\n",
    "        else:\n",
    "            top = np.where(intensity_scan > 0.2)[0][0]\n",
    "        return top\n",
    "\n",
    "    def find_peaks(self, i, tops):\n",
    "        im_i = pl.imread(self.file_list[i])\n",
    "        # crop the trench region\n",
    "        im_trenches = im_i[tops[0]:tops[0] + self.trench_length]\n",
    "        im_trenches_perc = np.percentile(im_trenches, 80, axis=0)\n",
    "        # normalize intensity\n",
    "        im_min = im_trenches_perc.min()\n",
    "        im_max = im_trenches_perc.max()\n",
    "        scaling_factor = (im_max - im_min)\n",
    "        im_trenches_perc = (im_trenches_perc - im_min)\n",
    "        im_trenches_perc = (im_trenches_perc / scaling_factor)\n",
    "        peak = self.detect_peaks(im_trenches_perc, mph=0.15, mpd=self.trench_width)\n",
    "        new_peak = self.peak_correct(peak, im_trenches_perc)\n",
    "        return new_peak\n",
    "\n",
    "    def peak_correct(self, old_peak, im_intensity):\n",
    "        half_trench_width = int(self.trench_width/2)\n",
    "        new_peaks = [old_peak[0]]\n",
    "        for p in old_peak[1:-1]:\n",
    "            half_p_height = int(im_intensity[p]/2) # int\n",
    "            full_peak = im_intensity[p - half_trench_width:p + half_trench_width+1]\n",
    "            p_tops  = np.where(full_peak>half_p_height)\n",
    "            p_left  = p - half_trench_width + p_tops[0][0]\n",
    "            p_right = p - half_trench_width + p_tops[0][-1]\n",
    "            p_corrected = int((p_left + p_right)/2)\n",
    "\n",
    "            new_peaks.append(p_corrected)\n",
    "        new_peaks.append(old_peak[-1])\n",
    "        return new_peaks\n",
    "\n",
    "    def get_trenches(self):\n",
    "        os.chdir(self.file_path)\n",
    "        # use the first 50 frames to identify trench relation\n",
    "        # TODO: change this part to add more flexibility, like backwards trench identification for persistors\n",
    "        frame_num = len(self.file_list)\n",
    "        # using the 85 percentile of the intensity of the first 50 frames as the meta-representation\n",
    "        im_stack = np.zeros((min(50, frame_num), self.height, self.width))\n",
    "        if self.found_drift:\n",
    "            self.read_drift()\n",
    "        for i in range(min(50, frame_num)):\n",
    "            im_i = pl.imread(self.file_list[i])\n",
    "            if np.max(im_i) > 255:\n",
    "                im_i = self.to_8_bit(im_i)\n",
    "            if self.found_drift== 1:\n",
    "\n",
    "                # correct for drift\n",
    "                # TODO: add y drift\n",
    "                move_x = self.drift_x[i]\n",
    "                move_y = self.drift_y[i]\n",
    "                temp = np.zeros((self.height, self.width))\n",
    "                if move_x>0:\n",
    "                    temp[:, :self.width-move_x] = im_i[:,move_x:]\n",
    "                else:\n",
    "                    temp[:,(-move_x):] = im_i[:,:self.width+move_x]\n",
    "\n",
    "                # if move_y>0:\n",
    "                #     temp[:self.width-move_y,:] = im_i[move_y:,:]\n",
    "                # else:\n",
    "                #     temp[(-move_y):,:] = im_i[:self.height+move_y,:]\n",
    "                im_i = temp\n",
    "\n",
    "            im_stack[i] = im_i\n",
    "        perc = np.percentile(im_stack, 85, axis=0).astype(np.uint8)\n",
    "        out_file = \"perc_85_frame_50_new.tiff\"\n",
    "\n",
    "        # convert to 8-bit, using the imageJ way\n",
    "        out = PIL.Image.frombytes(\"L\", (self.width, self.height), perc.tobytes())\n",
    "        out.save(out_file)\n",
    "\n",
    "\n",
    "        # identify tops & bottoms\n",
    "\n",
    "        if self.seg_channel == \"BF\" or self.seg_channel == \"Phase\":\n",
    "            intensity_scan = np.percentile(perc, 50, axis=1)\n",
    "        else:\n",
    "            intensity_scan = np.percentile(perc, 90, axis=1)\n",
    "\n",
    "\n",
    "        intensity_scan = intensity_scan / float(sum(intensity_scan))\n",
    "        # normalize intensity\n",
    "        im_min = intensity_scan.min()\n",
    "        im_max = intensity_scan.max()\n",
    "        scaling_factor = (im_max - im_min)\n",
    "        intensity_scan = (intensity_scan - im_min)\n",
    "        intensity_scan = (intensity_scan / scaling_factor)\n",
    "\n",
    "        if self.spatial != 1:  # top\n",
    "            top = np.where(intensity_scan > 0.2)[0][0] - 10\n",
    "            bottom = top + self.trench_length\n",
    "            self.tops.append(top)\n",
    "            self.bottoms.append(bottom)\n",
    "        if self.spatial != 0:  # bottom\n",
    "            bottom = np.where(intensity_scan > 0.2)[0][-1] + 10\n",
    "            top = bottom - self.trench_length\n",
    "            self.tops.append(top)\n",
    "            self.bottoms.append(bottom)\n",
    "\n",
    "        # identify trenches\n",
    "        peak_ind_dict = {}\n",
    "        if self.spatial == 2:\n",
    "            for i in range(2):\n",
    "                im_trenches = perc[self.tops[i]:self.bottoms[i]]\n",
    "                im_trenches_perc = np.percentile(im_trenches, 80, axis=0)\n",
    "\n",
    "                # normalize intensity\n",
    "                im_min = im_trenches_perc.min()\n",
    "                im_max = im_trenches_perc.max()\n",
    "                scaling_factor = (im_max - im_min)\n",
    "                im_trenches_perc = (im_trenches_perc - im_min)\n",
    "                im_trenches_perc = (im_trenches_perc / scaling_factor)\n",
    "                peak_ind = self.detect_peaks(im_trenches_perc, mph=0.35, mpd=self.trench_width)\n",
    "\n",
    "                # corrected\n",
    "                peak_ind = np.array(self.peak_correct(peak_ind,im_trenches_perc))\n",
    "\n",
    "                if peak_ind[0] < (self.trench_length / 2):\n",
    "                    peak_ind = peak_ind[1:]\n",
    "                if (self.width - peak_ind[-1]) < (self.trench_length / 2):\n",
    "                    peak_ind = peak_ind[:-1]\n",
    "                left_ind = np.array(peak_ind) - int(self.trench_width / 2)\n",
    "                right_ind = peak_ind + int(self.trench_width / 2)\n",
    "                ind_list = list(zip(left_ind, right_ind))\n",
    "                ind_list = np.array(ind_list)\n",
    "                peak_ind_dict[i] = ind_list\n",
    "        else:\n",
    "            im_trenches = perc[self.tops[0]:self.bottoms[0]]\n",
    "            im_trenches_perc = np.percentile(im_trenches, 80, axis=0)\n",
    "            # normalize intensity\n",
    "            im_min = im_trenches_perc.min()\n",
    "            im_max = im_trenches_perc.max()\n",
    "            scaling_factor = (im_max - im_min)\n",
    "            im_trenches_perc = (im_trenches_perc - im_min)\n",
    "            im_trenches_perc = (im_trenches_perc / scaling_factor)\n",
    "            peak_ind = self.detect_peaks(im_trenches_perc, mph=0.35, mpd=self.trench_width)\n",
    "            if peak_ind[0] < (self.trench_length / 2):\n",
    "                peak_ind = peak_ind[1:]\n",
    "            if (self.width - peak_ind[-1]) < (self.trench_length / 2):\n",
    "                peak_ind = peak_ind[:-1]\n",
    "            left_ind = peak_ind - int(self.trench_width / 2)\n",
    "            right_ind = peak_ind + int(self.trench_width / 2)\n",
    "            ind_list = list(zip(left_ind, right_ind))\n",
    "            ind_list = np.array(ind_list)\n",
    "            peak_ind_dict[0] = ind_list\n",
    "\n",
    "        self.box_info = []\n",
    "        if self.spatial == 2:\n",
    "            h5_name_top = \"Lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_top.h5\"\n",
    "            self.box_info.append(h5_name_top)\n",
    "            hf_t = h5py.File(h5_name_top, 'w')\n",
    "            hf_t.create_dataset('box', data=peak_ind_dict[0])\n",
    "            hf_t.create_dataset('upper_index', data=self.tops[0])\n",
    "            hf_t.create_dataset('lower_index', data=self.bottoms[0])\n",
    "            hf_t.close()\n",
    "            h5_name_bottom = \"Lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_bottom.h5\"\n",
    "            self.box_info.append(h5_name_bottom)\n",
    "            hf_b = h5py.File(h5_name_bottom, 'w')\n",
    "            hf_b.create_dataset('box', data=peak_ind_dict[1])\n",
    "            hf_b.create_dataset('upper_index', data=self.tops[1])\n",
    "            hf_b.create_dataset('lower_index', data=self.bottoms[1])\n",
    "            hf_b.close()\n",
    "            # print(peak_ind_dict)\n",
    "        else:\n",
    "            local = ['top', 'bottom']\n",
    "            h5_name = \"Lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_\" + local[\n",
    "                self.spatial] + \".h5\"\n",
    "            self.box_info.append(h5_name)\n",
    "            hf = h5py.File(h5_name, 'w')\n",
    "            hf.create_dataset('box', data=peak_ind_dict[0])\n",
    "            hf.create_dataset('upper_index', data=self.tops[0])\n",
    "            hf.create_dataset('lower_index', data=self.bottoms[0])\n",
    "            hf.close()\n",
    "        return\n",
    "\n",
    "\n",
    "    def background_enhance(self):\n",
    "        self.get_file_list()  # run on original data\n",
    "        self.enhanced_path = self.file_path + '/enhanced'\n",
    "        # print(self.enhanced_path)\n",
    "#         try:\n",
    "#             os.makedirs(self.enhanced_path)\n",
    "#         except OSError:\n",
    "#             pass\n",
    "        os.makedirs(self.enhanced_path,exist_ok=True)\n",
    "            # for i in range(self.file_length):\n",
    "        for i in range(min(50,self.file_length)):\n",
    "            im_i = self.get_frame(i)\n",
    "            if np.max(im_i) > 255:\n",
    "                im_i = self.to_8_bit(im_i)\n",
    "\n",
    "            im_g = 255 * filters.gaussian(im_i, sigma=10)\n",
    "            im_i = (im_i - im_g)\n",
    "            im_i[im_i < 0] = 0\n",
    "            if self.is_stack:\n",
    "                new_name = self.file_list[0].split('/')[-1]\n",
    "                new_name = new_name.split('.')[0] + '_Time_' + str(i).zfill(3) + '.tiff'\n",
    "            else:\n",
    "                new_name = self.file_list[i].split('/')[-1]\n",
    "            cim = Image.fromarray((im_i).astype(np.uint8))\n",
    "            contrast = ImageEnhance.Contrast(cim)\n",
    "            cim = contrast.enhance(3)\n",
    "            cim.save(os.path.join(self.enhanced_path, new_name))\n",
    "        return\n",
    "\n",
    "    def enhance_kymo(self,im_i):\n",
    "        if np.max(im_i) > 255:\n",
    "            im_i = self.to_8_bit(im_i)\n",
    "        im_g = 255 * filters.gaussian(im_i, sigma=10)\n",
    "        im_i = (im_i - im_g)\n",
    "        im_i[im_i < 0] = 0\n",
    "        cim = Image.fromarray((im_i).astype(np.uint8))\n",
    "        contrast = ImageEnhance.Contrast(cim)\n",
    "        cim = contrast.enhance(3)\n",
    "        # cim.save(os.path.join(self.enhanced_path, new_name))\n",
    "        return np.array(cim)\n",
    "\n",
    "\n",
    "    # add spatial support\n",
    "    def auto_crop(self):\n",
    "        cropped_path = self.file_path + '/cropped'\n",
    "        self.cropped_path = cropped_path\n",
    "        # if not os.path.exists(cropped_path):\n",
    "#         try:\n",
    "#             os.makedirs(cropped_path)\n",
    "#         except OSError:\n",
    "#             pass\n",
    "        os.makedirs(cropped_path,exist_ok=True)\n",
    "        self.get_file_list(file_path=self.file_path + '/enhanced')\n",
    "        # for i in range(self.file_length):\n",
    "        for i in range(self.file_length):\n",
    "            im_i = self.get_frame(i)\n",
    "            if np.max(im_i) > 255:\n",
    "                im_i = self.to_8_bit(im_i)\n",
    "            if i == 0:\n",
    "                self.spread = list((map(self.N2spread, im_i > threshold_otsu(im_i) // 2)))\n",
    "                self.spread = np.array(self.spread) / self.width\n",
    "                self.spread = medfilt(self.spread, 29)\n",
    "                if self.spatial != 1:  # both have top\n",
    "                    # TODO: debugging here\n",
    "                    first_pass_thres = min(np.where(self.spread > 0.45)[0])\n",
    "\n",
    "                    # check if is the real top\n",
    "                    first_zero_after = min(np.where(self.spread[first_pass_thres:] < 0.1)[0])\n",
    "\n",
    "                    if (first_zero_after) < 0.8*self.trench_length:\n",
    "                        self.ytop_t = min(np.where(self.spread[first_zero_after+first_pass_thres:] > 0.45)[0])+first_pass_thres+first_zero_after\n",
    "                    else:\n",
    "                        self.ytop_t = first_pass_thres\n",
    "\n",
    "                    # to have consistent height\n",
    "                    self.ybot_t = self.ytop_t + self.trench_length\n",
    "\n",
    "                    # deal with bad position\n",
    "                    if self.ybot_t > self.height:\n",
    "                        out_string = \"Top of lane \" + self.lane + \" position \" + self.pos + \" may be a bad position. no kymograph will be generated on it.\"\n",
    "                        print(out_string)\n",
    "                        self.bad_pos[0] = 1\n",
    "\n",
    "                # For bottom, need a new attribute to store the original index\n",
    "                if self.spatial != 0:  # both have bottom\n",
    "                    first_pass_thres = max(np.where(self.spread > 0.45)[0])  # leave some space\n",
    "                    first_zero_after = min(np.where(self.spread[:-first_pass_thres] < 0.1)[0])\n",
    "                    if first_zero_after < 0.8*self.trench_length:\n",
    "                        self.ybot_b = max(np.where(self.spread[:-first_zero_after-first_zero_after] > 0.45)[0])\n",
    "                    else:\n",
    "                        self.ybot_b= first_pass_thres\n",
    "                    # to have consistent height\n",
    "                    self.ytop_b = self.ybot_b - self.trench_length\n",
    "\n",
    "                    # deal with bad position\n",
    "                    if self.ytop_b < 0:\n",
    "                        out_string = \"Bottom of lane \" + self.lane + \" position \" + self.pos + \" may be a bad position. no kymograph will be generated on it.\"\n",
    "                        print(out_string)\n",
    "                        self.bad_pos[1] = 1\n",
    "                    self.bottom_cut = self.ytop_b\n",
    "\n",
    "            if self.spatial != 1:  # both have top\n",
    "                cim = Image.fromarray(im_i[self.ytop_t:self.ybot_t, :].astype(np.uint8))\n",
    "                # get file name\n",
    "                if self.is_stack:\n",
    "                    new_name = self.file_list[0].split('/')[-1]\n",
    "                    new_name = 'Top_' + new_name.split('.')[0] + '_Time_' + str(i).zfill(3) + '.tiff'\n",
    "                else:\n",
    "                    new_name = 'Top_' + self.file_list[i].split('/')[-1]\n",
    "                cim.save(os.path.join(cropped_path, new_name))\n",
    "\n",
    "            if self.spatial != 0:  # both have bottom\n",
    "                cim = Image.fromarray(im_i[self.ytop_b:self.ybot_b, :].astype(np.uint8))\n",
    "                # get file name\n",
    "                if self.is_stack:\n",
    "                    new_name = self.file_list[0].split('/')[-1]\n",
    "                    new_name = 'Bottom_' + new_name.split('.')[0] + '_Time_' + str(i).zfill(3) + '.tiff'\n",
    "                else:\n",
    "                    new_name = 'Bottom_' + self.file_list[i].split('/')[-1]\n",
    "                cim.save(os.path.join(cropped_path, new_name))\n",
    "        return\n",
    "\n",
    "    def mask_all_trenches(self):\n",
    "        self.cropped_path = self.file_path + \"/cropped\"\n",
    "        if self.spatial != 1: # top\n",
    "            self.get_file_list(file_path=self.cropped_path, spatial='Top')\n",
    "            # use the first 50 frames to get rough trench mask\n",
    "            # convert to binary using max_entropy threshold\n",
    "            im_stack = np.zeros((min(50, self.file_length), self.height, self.width))\n",
    "            for i in range(min(50, self.file_length)):\n",
    "                im_i = self.get_frame(i)\n",
    "                thresh = threshold_otsu(im_i)\n",
    "                im_i = self.make_binary(im_i, thresh)\n",
    "                im_stack[i] = im_i\n",
    "            # take median\n",
    "            self.im_projected = np.ceil(np.percentile(im_stack, 70, axis=0)).astype(np.int8)\n",
    "            # thresh = threshold_otsu(im_projected)\n",
    "            out_file = \"Top_rough_mask.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, self.height), self.im_projected.tobytes())\n",
    "\n",
    "            out.save(out_file)\n",
    "            # only analysis the tip\n",
    "            sub_height = 50\n",
    "            im_tip = self.im_projected[:sub_height, :]\n",
    "            # remove small elements\n",
    "            tip_trench = label(im_tip)\n",
    "            reg_props = regionprops(tip_trench)\n",
    "            for reg in reg_props:\n",
    "                if reg.area < 50:\n",
    "                    reg_loc = reg.bbox\n",
    "                    filled_reg = np.zeros((reg_loc[2] - reg_loc[0], reg_loc[3] - reg_loc[1]))\n",
    "                    tip_trench[reg_loc[0]:reg_loc[2], reg_loc[1]:reg_loc[3]] = filled_reg\n",
    "            out_file = \"Top_small_particle_removed.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, sub_height), im_tip.tobytes())\n",
    "            out.save(out_file)\n",
    "            self.im_projected = im_tip\n",
    "            # vertical dilation\n",
    "            structure = np.zeros((9, 9))\n",
    "            structure[4, 4] = 1\n",
    "            structure[5, 4] = 1\n",
    "            structure[6, 4] = 1\n",
    "            structure[7, 4] = 1\n",
    "            structure[8, 4] = 1\n",
    "\n",
    "            # im_dilated = binary_dilation(im_closed,structure=structure, iterations=20)\n",
    "            im_dilated = binary_dilation(im_tip, structure=structure, iterations=20)\n",
    "            im_dilated = (255 * im_dilated).astype(np.int8)\n",
    "            out_file = \"Top_dilated_mask.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, sub_height), im_dilated.tobytes())\n",
    "            out.save(out_file)\n",
    "\n",
    "            # vertical dilation down\n",
    "            structure = np.zeros((9, 9))\n",
    "            structure[4, 4] = 1\n",
    "            structure[5, 4] = 1\n",
    "            structure[6, 4] = 1\n",
    "            structure[7, 4] = 1\n",
    "            structure[8, 4] = 1\n",
    "\n",
    "            # im_dilated = binary_dilation(im_closed,structure=structure, iterations=200)\n",
    "            im_dilated = binary_dilation(im_tip, structure=structure, iterations=200)\n",
    "            im_dilated = (255 * im_dilated).astype(np.int8)\n",
    "            out_file = \"Top_dilated_mask_after_closing_down.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, sub_height), im_dilated.tobytes())\n",
    "            out.save(out_file)\n",
    "\n",
    "            # vertical dilation up\n",
    "            structure = np.zeros((5, 5))\n",
    "            structure[0, 2] = 1\n",
    "            structure[1, 2] = 1\n",
    "            structure[2, 2] = 1\n",
    "            im_dilated = binary_dilation(im_dilated, structure=structure, iterations=4)\n",
    "            im_dilated = (255 * im_dilated).astype(np.int8)\n",
    "            out_file = \"Top_dilated_mask_after_closing_down_up.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, sub_height), im_dilated.tobytes())\n",
    "            out.save(out_file)\n",
    "\n",
    "            # find binding box\n",
    "            trench_ccomp = label(im_dilated)\n",
    "            self.reg_props = regionprops(trench_ccomp)\n",
    "            print(self.file_path,len(reg_props))\n",
    "            self.bbox_list = []\n",
    "            for reg in self.reg_props:\n",
    "                reg_width = reg.bbox[3] - reg.bbox[1]\n",
    "                # if the identified box is really a trench\n",
    "                # print(reg_width)\n",
    "                if self.trench_width * 0.7 < reg_width < self.trench_width * 1.3:\n",
    "                    # print('oh')\n",
    "                    self.bbox_list.append(reg.bbox)\n",
    "\n",
    "            self.bbox_list.sort(key=lambda x: x[1])\n",
    "            self.bbox_list = [(int(a + self.ytop_t), (int(a + self.ytop_t+self.trench_length)), int(b), int(d)) for a, b, c, d in self.bbox_list]\n",
    "            if len(self.bbox_list) == 0:  # no item found\n",
    "                self.bad_pos[0] = 1\n",
    "                out_msg = \"At lane\" +str(self.lane) + \" pos\" + str(self.pos) +\" something is wrong in region props for top trenches\"\n",
    "                print(out_msg)\n",
    "                return\n",
    "\n",
    "            # exclude edges\n",
    "            most_left = self.bbox_list[0]\n",
    "            most_right = self.bbox_list[-1]\n",
    "            if most_left[2] == 0:\n",
    "                self.bbox_list = self.bbox_list[1:]\n",
    "            if most_right[3] == self.width:\n",
    "                self.bbox_list = self.bbox_list[:-1]\n",
    "            self.bbox_dict[0] = self.bbox_list\n",
    "\n",
    "        if self.spatial != 0: # bottom\n",
    "            self.get_file_list(file_path=self.cropped_path, spatial='Bottom')\n",
    "            # use the first 50 frames to get rough trench mask\n",
    "            # convert to binary using max_entropy threshold\n",
    "            im_stack = np.zeros((min(50, self.file_length), self.height, self.width))\n",
    "            for i in range(min(50, self.file_length)):\n",
    "                im_i = self.get_frame(i)\n",
    "                thresh = threshold_otsu(im_i)\n",
    "                im_i = self.make_binary(im_i, thresh)\n",
    "                im_stack[i] = im_i\n",
    "            # take median\n",
    "            self.im_projected = np.ceil(np.percentile(im_stack, 70, axis=0)).astype(np.int8)\n",
    "            # thresh = threshold_otsu(im_projected)\n",
    "            out_file = \"Top_rough_mask.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, self.height), self.im_projected.tobytes())\n",
    "\n",
    "            out.save(out_file)\n",
    "            # only analysis the bot\n",
    "            sub_height = 50\n",
    "            im_bot = self.im_projected[self.height - sub_height:, :]\n",
    "            # remove small elements\n",
    "            bot_trench = label(im_bot)\n",
    "            reg_props = regionprops(bot_trench)\n",
    "            for reg in reg_props:\n",
    "                if reg.area < 50:\n",
    "                    reg_loc = reg.bbox\n",
    "                    filled_reg = np.zeros((reg_loc[2] - reg_loc[0], reg_loc[3] - reg_loc[1]))\n",
    "                    bot_trench[reg_loc[0]:reg_loc[2], reg_loc[1]:reg_loc[3]] = filled_reg\n",
    "            out_file = \"Bottom_small_particle_removed.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, sub_height), im_bot.tobytes())\n",
    "            out.save(out_file)\n",
    "            self.im_projected = im_bot\n",
    "            # vertical dilation\n",
    "            structure = np.zeros((9, 9))\n",
    "            # structure[4, 4] = 1\n",
    "            # structure[5, 4] = 1\n",
    "            # structure[6, 4] = 1\n",
    "            # structure[7, 4] = 1\n",
    "            # structure[8, 4] = 1\n",
    "            structure[0, 4] = 1\n",
    "            structure[1, 4] = 1\n",
    "            structure[2, 4] = 1\n",
    "            structure[3, 4] = 1\n",
    "            structure[4, 4] = 1\n",
    "\n",
    "\n",
    "            im_dilated = binary_dilation(im_bot, structure=structure, iterations=200)\n",
    "            im_dilated = (255 * im_dilated).astype(np.int8)\n",
    "            out_file = \"Bottom_dilated_mask.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, sub_height), im_dilated.tobytes())\n",
    "            out.save(out_file)\n",
    "\n",
    "            # vertical dilation up\n",
    "            structure = np.zeros((5, 5))\n",
    "            # structure[0, 2] = 1\n",
    "            # structure[1, 2] = 1\n",
    "            # structure[2, 2] = 1\n",
    "            structure[2, 2] = 1  #down\n",
    "            structure[3, 2] = 1\n",
    "            structure[4, 2] = 1\n",
    "            im_dilated = binary_dilation(im_dilated, structure=structure, iterations=4)\n",
    "            im_dilated = (255 * im_dilated).astype(np.int8)\n",
    "            out_file = \"Bottom_dilated_mask_after_closing_down_up.tiff\"\n",
    "            out = PIL.Image.frombytes(\"L\", (self.width, sub_height), im_dilated.tobytes())\n",
    "            out.save(out_file)\n",
    "\n",
    "            # find binding box\n",
    "            trench_ccomp = label(im_dilated)\n",
    "            self.reg_props = regionprops(trench_ccomp)\n",
    "            self.bbox_list = []\n",
    "            for reg in self.reg_props:\n",
    "                reg_width = reg.bbox[3] - reg.bbox[1]\n",
    "                # if the identified box is really a trench\n",
    "                if self.trench_width * 0.7 < reg_width < self.trench_width * 1.3:\n",
    "                    self.bbox_list.append(reg.bbox)\n",
    "\n",
    "            self.bbox_list.sort(key=lambda x: x[1])\n",
    "            # self.bbox_list = [(int(a + self.ytop), self.ybot, int(b), int(d)) for a, b, c, d in self.bbox_list]\n",
    "\n",
    "            self.bbox_list = [(int(c + self.bottom_cut-self.trench_length), int(c + self.bottom_cut), int(b), int(d))\n",
    "                              for a, b, c, d in self.bbox_list]\n",
    "\n",
    "            if len(self.bbox_list) == 0:  # no item found\n",
    "                self.bad_pos[1] = 1\n",
    "                out_msg = \"At lane\" + str(self.lane) + \" pos\" + str(self.pos) +\" something is wrong in region props for bottom trenches\"\n",
    "                print(out_msg)\n",
    "                return\n",
    "\n",
    "            # exclude edges\n",
    "            most_left = self.bbox_list[0]\n",
    "            most_right = self.bbox_list[-1]\n",
    "            if most_left[2] == 0:\n",
    "                self.bbox_list = self.bbox_list[1:]\n",
    "            if most_right[3] == self.width:\n",
    "                self.bbox_list = self.bbox_list[:-1]\n",
    "            self.bbox_dict[1] = self.bbox_list\n",
    "\n",
    "        # save box info:\n",
    "        self.box_info = []\n",
    "        if self.spatial !=1:\n",
    "            top_box = self.bbox_dict[0]\n",
    "            h5_name_top = str(self.seg_channel) + \"_lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_top.h5\"\n",
    "            h5_name_top = os.path.join(self.file_path, h5_name_top)\n",
    "            self.box_info.append(h5_name_top)\n",
    "\n",
    "            hf_t = h5py.File(h5_name_top, 'w')\n",
    "            hf_t.create_dataset('box', data=top_box)\n",
    "\n",
    "            hf_t.close()\n",
    "        if self.spatial !=0:\n",
    "            bot_box = self.bbox_dict[1]\n",
    "            h5_name_bot = str(self.seg_channel) + \"_lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_bottom.h5\"\n",
    "            h5_name_bot = os.path.join(self.file_path, h5_name_bot)\n",
    "            self.box_info.append(h5_name_bot)\n",
    "\n",
    "            hf_b = h5py.File(h5_name_bot, 'w')\n",
    "            hf_b.create_dataset('box', data=bot_box)\n",
    "            hf_b.close()\n",
    "        return\n",
    "\n",
    "    def clean_up(self):\n",
    "        shutil.rmtree(self.enhanced_path)\n",
    "        return\n",
    "\n",
    "    def run_kymo_phase(self):\n",
    "        # self.background_enhance()\n",
    "        # self.auto_crop()\n",
    "        # self.mask_all_trenches()\n",
    "        self.get_file_list()\n",
    "        self.background_enhance()\n",
    "        self.auto_crop()\n",
    "        self.mask_all_trenches()\n",
    "        self.kymograph()\n",
    "        if self.clean:\n",
    "            self.clean_up()\n",
    "        return\n",
    "\n",
    "    def kymograph(self):\n",
    "\n",
    "        if self.box_info is None:\n",
    "            self.box_info = []\n",
    "            if self.spatial == 2:\n",
    "                h5_name_top = \"Lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_top.h5\"\n",
    "                self.box_info.append(h5_name_top)\n",
    "                h5_name_bottom = \"Lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_bottom.h5\"\n",
    "                self.box_info.append(h5_name_bottom)\n",
    "            else:\n",
    "                local = ['top', 'bottom']\n",
    "                h5_name = \"Lane_\" + str(self.lane).zfill(2) + \"_pos_\" + str(self.pos).zfill(3) + \"_\" + local[\n",
    "                    self.spatial] + \".h5\"\n",
    "                self.box_info.append(h5_name)\n",
    "\n",
    "\n",
    "\n",
    "        os.chdir(self.file_path)\n",
    "        self.get_file_list()  # get file list\n",
    "        kymo_path = os.path.join(self.main_path, self.prefix, 'Kymograph')\n",
    "        kymo_path = kymo_path + \"/Lane_\" + str(self.lane).zfill(2)\n",
    "#         try:\n",
    "#             os.makedirs(kymo_path)\n",
    "#         except OSError:\n",
    "#             # print(\"?\")\n",
    "#             pass\n",
    "\n",
    "#         kymo_path = kymo_path + \"/pos_\" + str(self.pos).zfill(3)\n",
    "#         try:\n",
    "#             os.makedirs(kymo_path)\n",
    "#         except OSError:\n",
    "#             # print(\"??\")\n",
    "#             pass\n",
    "        \n",
    "        kymo_path = os.path.join(self.main_path, self.prefix, \n",
    "                                 'Kymograph',\"Lane_\" + str(self.lane).zfill(2),\n",
    "                                \"pos_\" + str(self.pos).zfill(3))\n",
    "        if self.saving_option != 1:\n",
    "            kymo_path_stack = os.path.join(kymo_path, \"Stack\")\n",
    "#             try:\n",
    "#                 os.makedirs(kymo_path_stack)\n",
    "#             except OSError:\n",
    "#                 pass\n",
    "            os.makedirs(kymo_path_stack,exist_ok=True)\n",
    "        if self.saving_option != 0:\n",
    "            kymo_path_kymo = os.path.join(kymo_path, \"Kymograph\")\n",
    "            \n",
    "\n",
    "#             try:\n",
    "#                 os.makedirs(kymo_path_kymo)\n",
    "#             except OSError:\n",
    "#                 pass\n",
    "            os.makedirs(kymo_path_kymo, exist_ok=True)\n",
    "\n",
    "        if self.kymo_enhance and ( self.channel==\"BF\" or self.channel==\"Phase\"):\n",
    "            for ii in range(len(self.box_info)):\n",
    "                hf = h5py.File(self.box_info[ii], 'r')\n",
    "                ind_list = hf.get('box').value\n",
    "                upper_index = hf.get('upper_index').value\n",
    "                lower_index = hf.get('lower_index').value\n",
    "                hf.close()\n",
    "                trench_num = len(ind_list)\n",
    "                if trench_num > 0:\n",
    "#                     all_kymo = {}\n",
    "                    h5py_name = os.path.join(os.getcwd(),self.channel + \"_all_kymo.h5\")\n",
    "                    all_kymo = h5py.File(h5py_name,\"a\")\n",
    "                    for t_i in range(trench_num):\n",
    "                        ds_name = str(t_i)\n",
    "                        \n",
    "                        all_kymo.create_dataset(ds_name, data=np.zeros((len(self.file_list), lower_index - upper_index, self.trench_width)))\n",
    "                    # file_list = ori_files[self.frame_start:self.frame_limit]\n",
    "                    for f_i in range(len(self.file_list)):\n",
    "                        try:\n",
    "                            file_i = self.file_list[f_i]\n",
    "                        except:\n",
    "                            print(\"something is wrong\")\n",
    "                            continue\n",
    "\n",
    "                        im_t = pl.imread(file_i)\n",
    "                        im_t = self.enhance_kymo(im_t)\n",
    "                        if self.found_drift == 1:\n",
    "                            self.read_drift()\n",
    "                            # correct for drift\n",
    "                            move_x = self.drift_x[f_i]\n",
    "                            move_y = self.drift_y[f_i]\n",
    "                        else:\n",
    "                            move_x = 0\n",
    "                            move_y = 0\n",
    "                        for t_i in range(trench_num):\n",
    "                            trench_left, trench_right = ind_list[t_i]\n",
    "                            trench = np.zeros((lower_index - upper_index, self.trench_width))\n",
    "                            try:\n",
    "                                trench[:, :max(0, trench_left + move_x) + self.trench_width] =\\\n",
    "                                    im_t[upper_index + move_y:lower_index + move_y, max(0,trench_left + move_x):\n",
    "                                                                                    max(0,trench_left + move_x) + self.trench_width]\n",
    "                            except:\n",
    "                                trench[:, :trench_left + self.trench_width] = im_t[upper_index:lower_index,\n",
    "                                                                              trench_left:trench_left + self.trench_width]\n",
    "#                             all_kymo[t_i][f_i] = trench.astype(np.uint16)\n",
    "                            all_kymo[ds_name][f_i] = trench.astype(np.uint16)\n",
    "                            \n",
    "\n",
    "                    for t_i in range(trench_num):\n",
    "                        trench_left, trench_right = ind_list[t_i]\n",
    "                        trench_middle = str(int((trench_left + trench_right) / 2))  # for the naming\n",
    "                        if \"_top\" in self.box_info[ii]:  # top trench\n",
    "                            if self.saving_option != 0:  # save kymo\n",
    "                                trench_name = kymo_path_kymo + \"/Kymo_enhanced_Lane_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_top_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                            if self.saving_option != 1:  # save stacks\n",
    "                                trench_name_stack = kymo_path_stack + \"/Stack_enhanced_Lane_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_top_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                        else:  # bottom trench\n",
    "                            if self.saving_option != 0:  # save kymo\n",
    "                                trench_name = kymo_path_kymo + \"/Kymo_enhanced_Lane_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_bottom_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                            if self.saving_option != 1:  # save stack\n",
    "                                trench_name_stack = kymo_path_stack + \"/Stack_Lane_enhanced_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_bottom_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                        this_kymo=all_kymo[str(t_i)][()].astype(np.uint16)\n",
    "                        if self.saving_option != 1:  # save stacks\n",
    "                            \n",
    "                            imsave(trench_name_stack,  this_kymo)\n",
    "                        if self.saving_option != 0:  # save kymo\n",
    "                            this_kymo = np.concatenate(this_kymo, axis=1).astype(np.uint16)\n",
    "                            out = PIL.Image.frombytes(\"I;16\", (this_kymo.shape[1], this_kymo.shape[0]), this_kymo.tobytes())\n",
    "                            out.save(trench_name)\n",
    "#                         all_kymo[t_i] = None\n",
    "                    all_kymo.close()\n",
    "                    os.remove(h5py_name)\n",
    "                else:\n",
    "                    print(\"no trenches detected\")\n",
    "\n",
    "        else:\n",
    "            for ii in range(len(self.box_info)):\n",
    "                hf = h5py.File(self.box_info[ii], 'r')\n",
    "                ind_list = hf.get('box').value\n",
    "                upper_index = hf.get('upper_index').value\n",
    "                lower_index = hf.get('lower_index').value\n",
    "                hf.close()\n",
    "                trench_num = len(ind_list)\n",
    "                if trench_num > 0:\n",
    "#                     all_kymo = {}\n",
    "#                     for t_i in range(trench_num):\n",
    "#                         all_kymo[t_i] = np.zeros((len(self.file_list), lower_index - upper_index, self.trench_width))\n",
    "                    # file_list = ori_files[self.frame_start:self.frame_limit]\n",
    "                    h5py_name = os.path.join(os.getcwd(),self.channel + \"_all_kymo.h5\")\n",
    "                    all_kymo = h5py.File(h5py_name,\"a\")\n",
    "                    for t_i in range(trench_num):\n",
    "                        ds_name = str(t_i)\n",
    "                        #print(ds_name)\n",
    "                        all_kymo.create_dataset(ds_name, data=np.zeros((len(self.file_list), lower_index - upper_index, self.trench_width)))\n",
    "\n",
    "                    for f_i in range(len(self.file_list)):\n",
    "                        try:\n",
    "                            file_i = self.file_list[f_i]\n",
    "                        except:\n",
    "                            print(\"something is wrong\")\n",
    "                            continue\n",
    "                        im_t = pl.imread(file_i)\n",
    "                        if self.found_drift == 1:\n",
    "                            self.read_drift()\n",
    "                            # correct for drift\n",
    "                            move_x = self.drift_x[f_i]\n",
    "                            move_y = self.drift_y[f_i]\n",
    "                        else:\n",
    "                            move_x = 0\n",
    "                            move_y = 0\n",
    "                        for t_i in range(trench_num):\n",
    "                            trench_left, trench_right = ind_list[t_i]\n",
    "                            trench = np.zeros((lower_index - upper_index, self.trench_width))\n",
    "                            try:\n",
    "                                trench[:, :max(0, trench_left + move_x) + self.trench_width] = \\\n",
    "                                    im_t[upper_index + move_y:lower_index + move_y, max(0, trench_left + move_x):\n",
    "                                                                                    max(0,\n",
    "                                                                                        trench_left + move_x) + self.trench_width]\n",
    "                            except:\n",
    "                                trench[:, :trench_left + self.trench_width] = im_t[upper_index:lower_index,\n",
    "                                                                              trench_left:trench_left + self.trench_width]\n",
    "                                all_kymo[ds_name][f_i] = trench.astype(np.uint16)\n",
    "#                             all_kymo[t_i][f_i] = trench.astype(np.uint16)\n",
    "\n",
    "                    for t_i in range(trench_num):\n",
    "                        trench_left, trench_right = ind_list[t_i]\n",
    "                        trench_middle = str(int((trench_left + trench_right) / 2))  # for the naming\n",
    "                        if \"_top\" in self.box_info[ii]:  # top trench\n",
    "                            if self.saving_option != 0:  # save kymo\n",
    "                                trench_name = kymo_path_kymo + \"/Kymo_Lane_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_top_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                            if self.saving_option != 1:  # save stacks\n",
    "                                trench_name_stack = kymo_path_stack + \"/Stack_Lane_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_top_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                        else:  # bottom trench\n",
    "                            if self.saving_option != 0:  # save kymo\n",
    "                                trench_name = kymo_path_kymo + \"/Kymo_Lane_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_bottom_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                            if self.saving_option != 1:  # save stack\n",
    "                                trench_name_stack = kymo_path_stack + \"/Stack_Lane_\" + str(self.lane).zfill(\n",
    "                                    2) + \"_pos_\" + str(\n",
    "                                    self.pos).zfill(3) + \"_trench_\" + str(t_i + 1).zfill(\n",
    "                                    2) + \"_bottom_x_middle_\" + trench_middle + \"_c_\" + self.channel + \".tiff\"\n",
    "                        \n",
    "                        this_kymo=all_kymo[str(t_i)][()].astype(np.uint16)\n",
    "                        if self.saving_option != 1:  # save stacks\n",
    "                            imsave(trench_name_stack, this_kymo)\n",
    "                        if self.saving_option != 0:  # save kymo\n",
    "                            this_kymo = np.concatenate(this_kymo, axis=1).astype(np.uint16)\n",
    "                            out = PIL.Image.frombytes(\"I;16\", (this_kymo.shape[1], this_kymo.shape[0]),\n",
    "                                                      this_kymo.tobytes())\n",
    "                            out.save(trench_name)\n",
    "                    all_kymo.close()\n",
    "                    os.remove(h5py_name)\n",
    "#                         all_kymo[t_i] = None\n",
    "                            \n",
    "                else:\n",
    "                    print(\"no trenches detected\")\n",
    "        return\n",
    "\n",
    "    def run_kymo(self):\n",
    "        self.get_file_list()\n",
    "        if self.channel == self.seg_channel:\n",
    "\n",
    "            if self.correct_drift == 1:\n",
    "                if self.seg_channel != 'BF' and self.seg_channel != 'Phase':\n",
    "\n",
    "                    self.find_drift()\n",
    "                else:\n",
    "\n",
    "                    self.find_drift_phase()\n",
    "            self.get_trenches()\n",
    "        self.kymograph()\n",
    "\n",
    "        return\n",
    "    \n",
    "    def run_kymo_cluster(self):\n",
    "        self.channel = self.seg_channel\n",
    "        self.get_file_list()\n",
    "\n",
    "        if self.correct_drift == 1:\n",
    "            if self.seg_channel != 'BF' and self.seg_channel != 'Phase':\n",
    "\n",
    "                self.find_drift()\n",
    "            else:\n",
    "\n",
    "                self.find_drift_phase()\n",
    "        self.get_trenches()\n",
    "        for channel in self.all_channels:\n",
    "            self.channel = channel\n",
    "            self.kymograph()\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def to_8_bit(im):\n",
    "        im_min = im.min()\n",
    "        im_max = im.max()\n",
    "        scaling_factor = (im_max - im_min)\n",
    "        im = (im - im_min)\n",
    "        im = (im * 255. / scaling_factor).astype(np.uint8)\n",
    "        return im\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='both', kpsh=False, valley=False, show=False, ax=None):\n",
    "        \"\"\"Detect peaks in data based on their amplitude and other features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 1D array_like\n",
    "            data.\n",
    "        mph : {None, number}, optional (default = None)\n",
    "            detect peaks that are greater than minimum peak height.\n",
    "        mpd : positive integer, optional (default = 1)\n",
    "            detect peaks that are at least separated by minimum peak distance (in\n",
    "            number of data).\n",
    "        threshold : positive number, optional (default = 0)\n",
    "            detect peaks (valleys) that are greater (smaller) than `threshold`\n",
    "            in relation to their immediate neighbors.\n",
    "        edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
    "            for a flat peak, keep only the rising edge ('rising'), only the\n",
    "            falling edge ('falling'), both edges ('both'), or don't detect a\n",
    "            flat peak (None).\n",
    "        kpsh : bool, optional (default = False)\n",
    "            keep peaks with same height even if they are closer than `mpd`.\n",
    "        valley : bool, optional (default = False)\n",
    "            if True (1), detect valleys (local minima) instead of peaks.\n",
    "        show : bool, optional (default = False)\n",
    "            if True (1), plot data in matplotlib figure.\n",
    "        ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ind : 1D array_like\n",
    "            indeces of the peaks in `x`.\n",
    "        \"\"\"\n",
    "\n",
    "        x = np.atleast_1d(x).astype('float64')\n",
    "        if x.size < 3:\n",
    "            return np.array([], dtype=int)\n",
    "        if valley:\n",
    "            x = -x\n",
    "        # find indices of all peaks\n",
    "        dx = x[1:] - x[:-1]\n",
    "        # handle NaN's\n",
    "        indnan = np.where(np.isnan(x))[0]\n",
    "        if indnan.size:\n",
    "            x[indnan] = np.inf\n",
    "            dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "        ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "        if not edge:\n",
    "            ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        else:\n",
    "            if edge.lower() in ['rising', 'both']:\n",
    "                ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "            if edge.lower() in ['falling', 'both']:\n",
    "                ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "        ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "        # handle NaN's\n",
    "        if ind.size and indnan.size:\n",
    "            # NaN's and values close to NaN's cannot be peaks\n",
    "            ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan - 1, indnan + 1))), invert=True)]\n",
    "        # first and last values of x cannot be peaks\n",
    "        if ind.size and ind[0] == 0:\n",
    "            ind = ind[1:]\n",
    "        if ind.size and ind[-1] == x.size - 1:\n",
    "            ind = ind[:-1]\n",
    "        # remove peaks < minimum peak height\n",
    "        if ind.size and mph is not None:\n",
    "            ind = ind[x[ind] >= mph]\n",
    "        # remove peaks - neighbors < threshold\n",
    "        if ind.size and threshold > 0:\n",
    "            dx = np.min(np.vstack([x[ind] - x[ind - 1], x[ind] - x[ind + 1]]), axis=0)\n",
    "            ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "        # detect small peaks closer than minimum peak distance\n",
    "        if ind.size and mpd > 1:\n",
    "            ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "            idel = np.zeros(ind.size, dtype=bool)\n",
    "            for i in range(ind.size):\n",
    "                if not idel[i]:\n",
    "                    # keep peaks with the same height if kpsh is True\n",
    "                    idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                           & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                    idel[i] = 0  # Keep current peak\n",
    "            # remove the small peaks and sort back the indices by their occurrence\n",
    "            ind = np.sort(ind[~idel])\n",
    "\n",
    "        if show:\n",
    "            if indnan.size:\n",
    "                x[indnan] = np.nan\n",
    "            if valley:\n",
    "                x = -x\n",
    "            _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
    "\n",
    "        return ind\n",
    "\n",
    "    @staticmethod\n",
    "    def pairwise_list_align(list_a, list_b, max_gap):\n",
    "        # print(list_b)\n",
    "        # print(max_gap)\n",
    "        shift = 0\n",
    "        matches = 0\n",
    "        i_b = 0\n",
    "        len_b = len(list_b)\n",
    "        # only consider middle\n",
    "        list_a = list_a[1:-1]\n",
    "        for x in list_a:\n",
    "            found = 0\n",
    "            while (not found) and (i_b < len_b):\n",
    "                # print(\"list_b \", list_b[i_b])\n",
    "                # print(\"list_a \", x)\n",
    "                diff = list_b[i_b] - x\n",
    "\n",
    "                if diff < -max_gap:\n",
    "                    i_b += 1\n",
    "                    len_b -= 1\n",
    "                elif diff > max_gap:  # this cell is lost\n",
    "                    break\n",
    "                else:\n",
    "                    found = 1\n",
    "                    shift += diff\n",
    "                    matches += 1\n",
    "                    i_b += 1  # don't compare with the matched one for the next cell\n",
    "                    len_b -= 1\n",
    "\n",
    "        if matches:\n",
    "            shift = shift * 1. / matches\n",
    "\n",
    "        return shift\n",
    "\n",
    "    # Max entropy algorithm\n",
    "    @staticmethod\n",
    "    def max_entropy(data):\n",
    "        # flatten the data\n",
    "        data = data.flatten()\n",
    "        data = np.sort(data)\n",
    "\n",
    "        # histogram\n",
    "        hist_v = np.histogram(data, bins=data.max())[0]\n",
    "        # normalize hist\n",
    "        hist_v = hist_v * 1. / len(data)\n",
    "        # CDF\n",
    "        cdf = hist_v.cumsum()\n",
    "        # print(cdf)\n",
    "        max_ent, threshold = 0, 0\n",
    "        for i in range(len(cdf)):\n",
    "            # for i in range(255):\n",
    "            # low range\n",
    "            cl = cdf[i]\n",
    "            sub_hist = hist_v[:i + 1] / cl\n",
    "            tot_ent = - np.sum(sub_hist * np.log(sub_hist))\n",
    "\n",
    "            # high range\n",
    "            ch = 1 - cl\n",
    "            if ch > 0:\n",
    "                sub_hist = hist_v[i:] / ch\n",
    "                tot_ent -= np.sum(sub_hist * np.log(sub_hist))\n",
    "\n",
    "                if tot_ent > max_ent:\n",
    "                    max_ent, threshold = tot_ent, i\n",
    "\n",
    "        return threshold\n",
    "\n",
    "    @staticmethod\n",
    "    def make_binary(im, threshold):\n",
    "        im = im > threshold\n",
    "        im = im.astype(int) * 255\n",
    "        return im\n",
    "\n",
    "    @staticmethod\n",
    "    def N2spread(x):\n",
    "        # get nonzero elements\n",
    "        ix = np.where(x > 0)[0]\n",
    "        # except empty signal\n",
    "        if len(ix) < 1:\n",
    "            return 0\n",
    "        return np.mean(abs(ix[0] - ix))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Parameters as in old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = r\"/n/scratch2/sw260/20181127\"\n",
    "nd2_file = \"SB1_SJC110_EZRDM_L35W1.5.nd2\"\n",
    "os.chdir(main_directory)\n",
    "lanes = range(1, 10)  # has to be a list lanes = [1,3,5]\n",
    "poses = range(1, 51)  # second value exclusive\n",
    "\n",
    "seg_channel = 'BF'\n",
    "\n",
    "other_channels = ['YFP'] # has to be a list\n",
    "\n",
    "# in pixels, measure in FIJI with a rectangle\n",
    "trench_width = 11\n",
    "trench_length = 190\n",
    "spatial = 2 #0=TOP, 1=BOTTOM, 2= TOP & BOTTOM\n",
    "frame_start = 0 #index start in 0\n",
    "\n",
    "\n",
    "# Some default parameters, change accordingly\n",
    "correct_drift = 1  # if want correction for drift, set to 1\n",
    "template = [380,520,380,1800]\n",
    "kymo_enhanced = 1\n",
    "\n",
    "\n",
    "frame_limit = None\n",
    "output_dir = None\n",
    "box_info = None\n",
    "saving_option = 0   # 0 for only stack, 1 for kymograph, 2 for both\n",
    "clean_up = 0 #remove phase contrast intermediate processes (put to 0 to check how kymograph is working)\n",
    "chip_length = None #give the lenfth in micron\n",
    "chip_width = None\n",
    "magnification = None #magnification used for Ti3/Ti4 scopes\n",
    "\n",
    "# TODO: Don't touch me!\n",
    "found_drift = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave me alone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Parallel processing\n",
    "def generator_cluster(nd2_file, main_directory, lane, pose, other_channels, seg_channel,  trench_length, \n",
    "                          trench_width, spatial, correct_drift=0, found_drift=0, frame_start=None, \n",
    "                          frame_limit=None, output_dir=None, box_info=None, saving_option = 0, \n",
    "                          clean_up=1, chip_length=None, chip_width=None, magnification = None,template=None,\n",
    "                          kymo_enhanced=0,core_fract=1):\n",
    "    ##### initiate new class object\n",
    "    new_kymo = trench_kymograph(nd2_file, main_directory, lane, pose, seg_channel,other_channels,spatial, trench_length,\n",
    "                                                trench_width, correct_drift, found_drift, frame_start, frame_limit,\n",
    "                                                output_dir, box_info, saving_option, clean_up, chip_length, chip_width, magnification,template,kymo_enhanced)\n",
    "    \n",
    "    new_kymo.run_kymo_cluster()\n",
    "    return \n",
    "#     ##### find trenches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying parameters for cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers_init = 50        # number of paraellel workers you want, each workers will work on one positions\n",
    "worker_memory = '4GB'      # memory for each worker, has to be equal or larger than the size of each position folder\n",
    "running_time  = '4:00:00'  # hh:mm:ss, estimation of total running time, depends on number of workers and file size. \n",
    "                           # 4 hours should be sufficient for most of the time\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beg for resources from O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(queue=\"short\",walltime=running_time,job_cpu=1,job_mem=worker_memory,cores=1,processes=1,memory=worker_memory)\n",
    "cluster.start_workers(n_workers_init)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fasten your seatbelt and get job running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb920e804514408b17efb5f310a8d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind_args= list(itertools.product(list(lanes),list(poses)))\n",
    "\n",
    "futures = []\n",
    "\n",
    "def run_generator_cluster(arg):\n",
    "    start_t = datetime.now()\n",
    "    lane, pose = arg\n",
    "    generator_cluster(nd2_file, main_directory, lane, pose, other_channels, seg_channel,  trench_length, \n",
    "                          trench_width, spatial, correct_drift=0, found_drift = 0, frame_start=None, \n",
    "                          frame_limit=None, output_dir=None, box_info=None, saving_option = 0, \n",
    "                          clean_up=1, chip_length=None, chip_width=None, magnification = None,template=None,\n",
    "                          kymo_enhanced=0,core_fract=1)\n",
    "    mem_usage = str(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1000.)+\"MB\"\n",
    "    print(mem_usage)\n",
    "    \n",
    "    time_elapsed = datetime.now() - start_t\n",
    "    print('Time elapsed for extraction (hh:mm:ss.ms) {}'.format(time_elapsed))\n",
    "\n",
    "fut = client.map(run_generator_cluster,ind_args)\n",
    "futures.append(fut)\n",
    "\n",
    "all_futures = [f for sublist in futures for f in sublist]\n",
    "\n",
    "dask.distributed.progress(all_futures)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check worker status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.120.16.233:57358\n",
       "  <li><b>Dashboard: </b><a href='http://10.120.16.233:8787/status' target='_blank'>http://10.120.16.233:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>50</li>\n",
       "  <li><b>Cores: </b>50</li>\n",
       "  <li><b>Memory: </b>200.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.120.16.233:57358' processes=50 cores=50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
